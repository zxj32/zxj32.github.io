{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDL_uncertainty_regularization.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZzktXBGXY_b",
        "colab_type": "text"
      },
      "source": [
        "# AAAI 2019 FALL SYMPOSIUM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JGndWTeOqc7K"
      },
      "source": [
        "### ### Quantifying Classification Uncertainty using Regularized Evidential Neural Networks\n",
        "### Xujiang Zhao\n",
        "### Yuzhe Ou"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvTWo1u6o8cP",
        "colab_type": "text"
      },
      "source": [
        "## Mathematical background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1vYcrGkqk0X",
        "colab_type": "text"
      },
      "source": [
        "Traditional deep neural nets (NNs) have shown the state-of-the-art performance in the task of classification in various applications. However, NNs have not considered any types of uncertainty associated with the class probabilities\n",
        "to minimize risk due to misclassification under uncertainty in real life. Unlike Bayesian neural nets indirectly infering uncertainty through weight uncertainties, evidential neural networks (ENNs) have been recently proposed to support explicit modeling of the uncertainty of class probabilities.  It treats predictions of an NN as subjective opinions and learns the function by collecting the evidence leading to these opinions by a deterministic NN from data. However, an ENN is trained as a black box without explicitly considering different types of inherent data uncertainty, such as vacuity (uncertainty due to a lack of evidence) or dissonance (uncertainty due to conflicting evidence). This paper presents a new approach, called a regularized ENN, that learns an ENN based on regularizations related to different characteristics of inherent data uncertainty. Via the experiments with both synthetic and real-world datasets, we demonstrate that the proposed regularized ENN can better learn of an ENN modeling different types of uncertainty in the class probabilities for classification tasks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n427qvhWqnr8",
        "colab_type": "text"
      },
      "source": [
        "### Theory of Evidence\n",
        "Suppose that there are $K$ outputs of an NN. Then we can write the following equality\n",
        "$$u + \\sum_{k = 1}^{K} b_k = 1$$\n",
        "where $b_k$ corresponds to $k^{th}$ ReLU output which will be interpreted as the *belief mass* of the $k^{th}$ class and $u$ is the *uncertainty mass* of the particular outputs.\n",
        "\n",
        "Each $b_k$ is defined as follows\n",
        "$$b_k =\\frac{e_k}{S}$$\n",
        "where $e_k$ is the evidence of the $k^{th}$ class and $S$ is the strength of the Dirichlet we'll use and defined as \n",
        "$$S = \\sum_{k = 1}^{K} (e_k + 1)$$\n",
        "which leaves $u$ the following portion\n",
        "$$u = \\frac{K}{S}$$\n",
        "\n",
        "\n",
        "Replacing $e_k + 1$ with $a_k$\n",
        "$$\\alpha_k = e_k + 1$$\n",
        "and using the resultant simplex vector $a$ in a Dirichlet as the density\n",
        "$$\n",
        "D(\\boldsymbol{p}|\\boldsymbol{\\alpha}) = \\begin{cases} \n",
        "      \\frac{1}{B(\\boldsymbol{\\alpha})} \\prod_{i=1}^{K} p_i^{\\alpha_i - 1} & \\text{for } \\boldsymbol{p} \\in \\mathcal{S}_K \\\\\n",
        "      0 & \\text{otherwise}\n",
        "   \\end{cases}\n",
        "$$\n",
        "\n",
        "As a result, we can define $\\mathcal{S}_K$ as \n",
        "$$\\mathcal{S}_K = \\{ \\boldsymbol{p} | \\sum_{i=1}^K p_i = 1 \\text{ and } 0 \\leq p_1,...,p_K \\leq 1 \\}$$\n",
        "and the probability of $k^{th}$ can still be calculated as\n",
        "$$\\hat{p}_k = \\frac{\\alpha_k}{S}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSp7UTYKtV9z",
        "colab_type": "text"
      },
      "source": [
        "### Loss Functions\n",
        "\n",
        "\n",
        "\n",
        "####  Using sum of squares loss - will be mentioned as *Eqn. 9* (as in the paper)\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_i(\\Theta) =\n",
        "\\int ||\\boldsymbol{y}_i - \\boldsymbol{p}_i||_2^2 \\frac{1}{B(\\alpha_i)} \\prod_{j=1}^K p_{ij}^{\\alpha_{ij} -1 } d\\boldsymbol{p}_i \n",
        "= \\sum_{j=1}^K \\mathbb{E}[(y_{ij} - p_{ij})^2]\n",
        "$$\n",
        "\n",
        "$$\n",
        "= \\sum_{j=1}^K \\mathbb{E}[y_{ij}^2 - 2 y_{ij}p_{ij} + p_{ij}^2] \n",
        "= \\sum_{j=1}^K (y_{ij}^2 - 2 y_{ij}\\mathbb{E}[p_{ij}] + \\mathbb{E}[p_{ij}^2])\n",
        "$$\n",
        "\n",
        "$$\n",
        "= \\sum_{j=1}^K (y_{ij}^2 - 2 y_{ij}\\mathbb{E}[p_{ij}] + \\mathbb{E}[p_{ij}]^2 + \\text{Var}(p_{ij}))\n",
        "= \\sum_{j=1}^K (y_{ij} - \\mathbb{E}[p_{ij}])^2 + \\text{Var}(p_{ij})\n",
        "$$\n",
        "\n",
        "$$\n",
        "= \\sum_{j=1}^K (y_{ij}^2 - 2 y_{ij}\\mathbb{E}[p_{ij}] + \\mathbb{E}[p_{ij}]^2 + \\text{Var}(p_{ij}))\n",
        "= \\sum_{j=1}^K (y_{ij} - \\mathbb{E}[p_{ij}])^2 + \\text{Var}(p_{ij})\n",
        "$$\n",
        "\n",
        "$$\n",
        "= \\sum_{j=1}^K (y_{ij} - \\frac{\\alpha_{ij}}{S_i})^2 + \\frac{\\alpha_{ij}(S_i - \\alpha_{ij})}{S_i^2(S_i + 1)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "= \\sum_{j=1}^K (y_{ij} - \\hat{p}_{ij})^2 + \\frac{\\hat{p}_{ij}(1 - \\hat{p}_{ij})}{(S_i + 1)}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm9FrWhpu8Ok",
        "colab_type": "text"
      },
      "source": [
        "### Regularization with KL Divergence\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\Theta) = \\sum_{i=1}^N \\mathcal{L}_i(\\Theta) + \\lambda_t \\sum_{i=1}^N KL[ D(\\boldsymbol{p}_i|\\boldsymbol{\\widetilde{\\alpha}}_i)||  D(\\boldsymbol{p}_i|\\langle 1,...,1 \\rangle )]\n",
        "$$\n",
        "\n",
        "where $\\lambda_t$ is annealed during the training by starting from 0 up to 1.\n",
        "\n",
        "After the derivations, KL term turns out to be in the following form\n",
        "$$\n",
        "KL[ D(\\boldsymbol{p}_i|\\boldsymbol{\\widetilde{\\alpha}}_i)||  D(\\boldsymbol{p}_i|\\langle 1,...,1 \\rangle )] = log(\\frac{\\Gamma(\\sum_{k=1}^K \\widetilde{\\alpha}_{ik})}{\\Gamma(K)\\prod_{k=1}^K\\Gamma(\\widetilde{\\alpha}_{ik})}) + \\sum_{k=1}^K (\\widetilde{\\alpha}_{ik} - 1) [\\psi(\\widetilde{\\alpha}_{ik}) - \\psi(\\sum_{k=1}^K \\widetilde{\\alpha}_{ik})]\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoqFBVTlquea",
        "colab_type": "text"
      },
      "source": [
        "### Regularization with Vacuity uncertainty\n",
        "To improve the perfomance of out-of-distribution detection, we introduce the uncertainty regularization to object function.\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\Theta) = \\mathbb{E}_{({\\bf x}_i, {\\bf y}_i) \\sim \\mathcal{D}}[\\mathcal{L}(f({\\bf x}_i|\\Theta), {\\bf y}_i) ] -\\nonumber \\\\\n",
        " \\lambda_1   \\mathbb{E}_{({\\bf x}_i, {\\bf y}_i) \\sim \\mathcal{D}_{\\text{OOD}}}[\\text{Vac}(f({\\bf x}_i|\\Theta))] - \\nonumber \\\\\n",
        " \\lambda_2   \\mathbb{E}_{({\\bf x}_i, {\\bf y}_i) \\sim \\mathcal{D}_{\\text{BOD}}}[\\text{Diss}(f({\\bf x}_i|\\Theta))],\n",
        "$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKXIgieTv61Y",
        "colab_type": "text"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqVmjwRGXu4B",
        "colab_type": "text"
      },
      "source": [
        "##### Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuoA1kVmWnT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist.input_data import read_data_sets as mnist_data_downloader\n",
        "from tensorflow.keras.datasets.cifar10 import load_data as cifar_data_downloader\n",
        "\n",
        "import scipy.ndimage as nd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "\n",
        "import scipy.stats\n",
        "import scipy.io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beLRC-JWZYN8",
        "colab_type": "text"
      },
      "source": [
        "##### Download datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU597FW9W7QA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get mnist dataset\n",
        "mnist = mnist_data_downloader('MNIST_data', one_hot=True)\n",
        "\n",
        "#get cifar dataset\n",
        "(cifar10_x_train, cifar10_y_train), (cifar10_x_test, cifar10_y_test) = cifar_data_downloader()\n",
        "cifar10_x_train = cifar10_x_train.reshape(50000, 32*32*3) / 255\n",
        "cifar10_y_train = cifar10_y_train.reshape(50000)\n",
        "cifar10_x_test = cifar10_x_test.reshape(10000, 32*32*3) / 255\n",
        "cifar10_y_test = cifar10_y_test.reshape(10000)\n",
        "\n",
        "cifar5_x_train = cifar10_x_train[cifar10_y_train<5,:]\n",
        "cifar5_y_train = cifar10_y_train[cifar10_y_train<5]\n",
        "\n",
        "cifar5_x_train_test = cifar10_x_test[cifar10_y_test<5,:]\n",
        "cifar5_y_train_test = cifar10_y_test[cifar10_y_test<5]\n",
        "\n",
        "cifar5_x_test = cifar10_x_train[cifar10_y_train>=5,:]\n",
        "cifar5_y_test = cifar10_y_train[cifar10_y_train>=5]\n",
        "\n",
        "cifar5_x_ood_train = cifar5_x_test[cifar5_y_test>=8,:]\n",
        "cifar5_y_ood_train = cifar5_y_test[cifar5_y_test>=8]\n",
        "cifar5_x_ood_test = cifar5_x_test[cifar5_y_test<8,:]\n",
        "cifar5_y_ood_test = cifar5_y_test[cifar5_y_test<8]\n",
        "print(cifar5_y_ood_train)\n",
        "print(cifar5_y_ood_test)\n",
        "cifar5_y_train = np.eye(5)[cifar5_y_train]\n",
        "cifar5_y_test = np.eye(5)[cifar5_y_test - 5]\n",
        "cifar5_y_ood_train = np.eye(5)[cifar5_y_ood_train - 5]\n",
        "cifar5_y_ood_test = np.eye(5)[cifar5_y_ood_test - 5]\n",
        "cifar5_y_train_test = np.eye(5)[cifar5_y_train_test]\n",
        "\n",
        "#download notmnist dataset\n",
        "!wget http://yaroslavvb.com/upload/notMNIST/notMNIST_small.mat\n",
        "  \n",
        "notmnist = scipy.io.loadmat(\"notMNIST_small.mat\")\n",
        "notmnist_x = np.array(notmnist[\"images\"]).reshape(28*28,18724).transpose() / 255\n",
        "notmnist_y = np.eye(10)[np.array(notmnist[\"labels\"]).astype(int)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O1iH8BBHtwK",
        "colab_type": "text"
      },
      "source": [
        "#####  <font color=yellow>(Get bounday data )</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC_mK_3CHyEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.stats import entropy\n",
        "\n",
        "def sample_mask(idx, l):\n",
        "    \"\"\"Create mask.\"\"\"\n",
        "    mask = np.zeros(l)\n",
        "    mask[idx] = 1\n",
        "    return np.array(mask, dtype=np.bool)\n",
        "\n",
        "dissonance_sample = 10 ## number of top dissonance node to choose\n",
        "sample_k = 10 ## number of nearest label node to choose\n",
        "bsize = 1000\n",
        "n_batches = cifar5_x_train.shape[0] // bsize\n",
        "\n",
        "dissonance_mask = []\n",
        "for i in range(n_batches):\n",
        "      data = cifar5_x_train[i*bsize:min((i+1)*bsize, cifar5_x_train.shape[0]),:]\n",
        "      label = cifar5_y_train[i*bsize:min((i+1)*bsize, cifar5_y_train.shape[0]),:]\n",
        "      score = cosine_similarity(data, data)\n",
        "      score_list = []\n",
        "      for item in score:\n",
        "        item_index = item.argsort()[-sample_k:][::-1]\n",
        "        near_label = label[item_index]\n",
        "        d_score = np.sum(near_label, axis=0)/sample_k\n",
        "        d_score = entropy(d_score)\n",
        "        score_list.append(d_score)\n",
        "      score_list = np.asarray(score_list)\n",
        "      dissonance_index = score_list.argsort()[-dissonance_sample:][::-1]\n",
        "      mask_i = sample_mask(dissonance_index, label.shape[0])\n",
        "      dissonance_mask.append(mask_i)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BFpnkNgXFJU",
        "colab_type": "code",
        "outputId": "1c901553-20e5-40fb-966b-525afdac95ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "# display a couple of pictures from the dataset\n",
        "\n",
        "digit = mnist.train.images[4].copy()\n",
        "digit2 = mnist.train.images[222].copy()\n",
        "\n",
        "i = 0\n",
        "plt.figure(figsize=(10,10))\n",
        "for image, size in ((digit, (28,28)), \n",
        "                    (digit2, (28,28)), \n",
        "                    (cifar5_x_train[1], (32,32,3)),\n",
        "                    (cifar5_x_train[23], (32,32,3)),\n",
        "                    (cifar5_x_ood_train[4], (32,32,3)),\n",
        "                    (cifar5_x_ood_test[11], (32,32,3)),\n",
        "                    (notmnist_x[6], (28, 28)),\n",
        "                    (notmnist_x[7], (28,28))):\n",
        "  i+=1\n",
        "  plt.subplot(1,8,i)\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image.copy().reshape(size))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAABeCAYAAAAHQJEfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgFhHVBYZp_2",
        "colab_type": "text"
      },
      "source": [
        "##### Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUE1hFXeXXB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Logit to evidence converters - activation functions (they have to produce non-negative outputs for the uncertaintyuncertainity process)\n",
        "\n",
        "def relu_evidence(logits):\n",
        "    return tf.nn.relu(logits)\n",
        "\n",
        "def exp_evidence(logits): \n",
        "    return tf.exp(logits/100)\n",
        "  \n",
        "def relu6_evidence(logits):\n",
        "    return tf.nn.relu6(logits)\n",
        "  \n",
        "def softsign_evidence(logits):\n",
        "    return tf.nn.softsign(logits)\n",
        "\n",
        "  \n",
        "#### KL Divergence calculator\n",
        "\n",
        "def KL(alpha, K):\n",
        "    beta=tf.constant(np.ones((1,K)),dtype=tf.float32)\n",
        "    S_alpha = tf.reduce_sum(alpha,axis=1,keepdims=True)\n",
        "    \n",
        "    KL = tf.reduce_sum((alpha - beta)*(tf.digamma(alpha)-tf.digamma(S_alpha)),axis=1,keepdims=True) + \\\n",
        "         tf.lgamma(S_alpha) - tf.reduce_sum(tf.lgamma(alpha),axis=1,keepdims=True) + \\\n",
        "         tf.reduce_sum(tf.lgamma(beta),axis=1,keepdims=True) - tf.lgamma(tf.reduce_sum(beta,axis=1,keepdims=True))\n",
        "    return KL\n",
        "\n",
        "\n",
        "##### Loss functions (there are three different one defined in the papaer)\n",
        "def loss_eq6(p, alpha, K, global_step, annealing_step):\n",
        "    S = tf.reduce_sum(alpha, axis=1, keepdims=True)\n",
        "    loglikelihood = tf.reduce_sum((p-(alpha/S))**2, axis=1, keepdims=True) + tf.reduce_sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True)\n",
        "    KL_reg =  tf.minimum(1.0, tf.cast(global_step/annealing_step, tf.float32)) * KL((alpha - 1)*(1-p) + 1 , K)\n",
        "    return loglikelihood\n",
        "\n",
        "def loss_eq5(p, alpha, K, global_step, annealing_step):\n",
        "    S = tf.reduce_sum(alpha, axis=1, keepdims=True)\n",
        "    loglikelihood = tf.reduce_sum((p-(alpha/S))**2, axis=1, keepdims=True) + tf.reduce_sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True)\n",
        "    KL_reg =  tf.minimum(1.0, tf.cast(global_step/annealing_step, tf.float32)) * KL((alpha - 1)*(1-p) + 1 , K)\n",
        "    return loglikelihood + KL_reg\n",
        "\n",
        "def loss_eq4(p, alpha, K, global_step, annealing_step):\n",
        "    loglikelihood = tf.reduce_mean(tf.reduce_sum(p * (tf.digamma(tf.reduce_sum(alpha, axis=1, keepdims=True)) - tf.digamma(alpha)), 1, keepdims=True))\n",
        "    KL_reg =  tf.minimum(1.0, tf.cast(global_step/annealing_step, tf.float32)) * KL((alpha - 1)*(1-p) + 1 , K)\n",
        "    return loglikelihood + KL_reg\n",
        "\n",
        "def loss_eq3(p, alpha, K, global_step, annealing_step):\n",
        "    loglikelihood = tf.reduce_mean(tf.reduce_sum(p * (tf.log(tf.reduce_sum(alpha, axis=1, keepdims=True)) - tf.log(alpha)), 1, keepdims=True))\n",
        "    KL_reg =  tf.minimum(1.0, tf.cast(global_step/annealing_step, tf.float32)) * KL((alpha - 1)*(1-p) + 1 , K)\n",
        "    return loglikelihood + KL_reg\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoI6UKvm3vGF",
        "colab_type": "text"
      },
      "source": [
        "#####  <font color=yellow>Dissonance utility function</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjrC_n-D32jW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dissonance_tf(evidence):\n",
        "    alpha = evidence + 1.0\n",
        "    S = tf.reduce_sum(alpha, axis=1, keepdims=True)\n",
        "    belief = evidence / S\n",
        "    dis_un = 0\n",
        "    list_k = np.arange(5)\n",
        "    for i in range(5):\n",
        "      list_j = np.delete(list_k, i)\n",
        "      bal_i = belief[:, i]\n",
        "      dis_i = 0\n",
        "      score_ij = 0\n",
        "      score_j = 0\n",
        "      for j in list_j:\n",
        "        bal_j = belief[:, j]\n",
        "        bal_ij = Bal_tf(bal_i, bal_j)\n",
        "        score_ij += bal_ij * bal_j\n",
        "        score_j += bal_j \n",
        "      dis_i += bal_i * score_ij / (score_j + 1e-8)\n",
        "      dis_un += dis_i\n",
        "    return dis_un\n",
        "        \n",
        " \n",
        "def Bal_tf(b_i, b_j):\n",
        "    result = 1 - tf.abs(b_i - b_j) / (b_i + b_j + 1e-8)\n",
        "    return result\n",
        "  \n",
        "def masked_dissonance_loss(loss, mask):\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    mask /= tf.reduce_mean(mask)\n",
        "    loss *= mask\n",
        "    return tf.reduce_mean(loss)\n",
        "  \n",
        "  \n",
        "def dissonance_uncertainty_edl(evidence):\n",
        "    alpha = evidence + 1.0\n",
        "    S = np.sum(alpha, axis=1, keepdims=True)\n",
        "    belief = evidence / S\n",
        "    dis_un = np.zeros_like(S)\n",
        "    for k in range(belief.shape[0]):\n",
        "        for i in range(belief.shape[1]):\n",
        "            bi = belief[k][i]\n",
        "            term_Bal = 0.0\n",
        "            term_bj = 0.0\n",
        "            for j in range(belief.shape[1]):\n",
        "                if j != i:\n",
        "                    bj = belief[k][j]\n",
        "                    term_Bal += bj * Bal(bi, bj)\n",
        "                    term_bj += bj\n",
        "            dis_ki = bi * term_Bal / (term_bj + 1e-8)\n",
        "            dis_un[k] += dis_ki\n",
        " \n",
        "    return dis_un\n",
        " \n",
        "def Bal(b_i, b_j):\n",
        "    result = 1 - np.abs(b_i - b_j) / (b_i + b_j + 1e-8)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6UlDFVVzMwa",
        "colab_type": "code",
        "outputId": "dcf49363-ab43-4d5c-daba-53e5774d354d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "evi = np.array([[0.6, 0.01, 0.05]])\n",
        "diss = dissonance_uncertainty_edl(evi)\n",
        "print(diss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.02420771]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf_Me0zWq91H",
        "colab_type": "text"
      },
      "source": [
        "##### Drawing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCpeC9rgq-Bh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Graphs of total evidence & uncertainty for test/train datasets (plus their classification accuracies)\n",
        "\n",
        "def draw_EDL_results(K, train_acc1, train_ev_s, train_ev_f, test_acc1, test_ev_s, test_ev_f): \n",
        "    # calculate uncertainty for training and testing data for correctly and misclassified samples\n",
        "    train_u_succ = K / (K+np.array(train_ev_s))\n",
        "    train_u_fail = K / (K+np.array(train_ev_f))\n",
        "    test_u_succ  = K / (K+np.array(test_ev_s))\n",
        "    test_u_fail  = K / (K+np.array(test_ev_f))\n",
        "    \n",
        "    f, axs = pl.subplots(2, 2)\n",
        "    f.set_size_inches([10,10])\n",
        "    \n",
        "    axs[0,0].plot(train_ev_s,c='r',marker='+')\n",
        "    axs[0,0].plot(train_ev_f,c='k',marker='x')\n",
        "    axs[0,0].set_title('Train Data')\n",
        "    axs[0,0].set_xlabel('Epoch')\n",
        "    axs[0,0].set_ylabel('Estimated total evidence for classification') \n",
        "    axs[0,0].legend(['Correct Clasifications','Misclasifications'])\n",
        "    \n",
        "    axs[0,1].plot(train_u_succ,c='r',marker='+')\n",
        "    axs[0,1].plot(train_u_fail,c='k',marker='x')\n",
        "    axs[0,1].plot(train_acc1,c='blue',marker='*')\n",
        "    axs[0,1].set_title('Train Data')\n",
        "    axs[0,1].set_xlabel('Epoch')\n",
        "    axs[0,1].set_ylabel('Estimated uncertainty for classification')\n",
        "    axs[0,1].legend(['Correct clasifications','Misclasifications', 'Accuracy'])\n",
        "    \n",
        "    axs[1,0].plot(test_ev_s,c='r',marker='+')\n",
        "    axs[1,0].plot(test_ev_f,c='k',marker='x')\n",
        "    axs[1,0].set_title('Test Data')\n",
        "    axs[1,0].set_xlabel('Epoch')\n",
        "    axs[1,0].set_ylabel('Estimated total evidence for classification') \n",
        "    axs[1,0].legend(['Correct Clasifications','Misclasifications'])\n",
        "    \n",
        "    axs[1,1].plot(test_u_succ,c='r',marker='+')\n",
        "    axs[1,1].plot(test_u_fail,c='k',marker='x')\n",
        "    axs[1,1].plot(test_acc1,c='blue',marker='*')\n",
        "    axs[1,1].set_title('Test Data')\n",
        "    axs[1,1].set_xlabel('Epoch')\n",
        "    axs[1,1].set_ylabel('Estimated uncertainty for classification')\n",
        "    axs[1,1].legend(['Correct clasifications','Misclasifications', 'Accuracy'])\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "#### Graph for image rotation experiment\n",
        "\n",
        "def rotating_image_classification(img, sess, prob, X, keep_prob, K, uncertainty=None, dims=(28,28), threshold=0.25, c=['black','blue','brown','purple','cyan','red'], marker=['s','^','o']*2):\n",
        "    Mdeg = 180 \n",
        "    Ndeg = Mdeg//10+1\n",
        "    ldeg = []\n",
        "    lp = []\n",
        "    lu = []\n",
        "    scores = np.zeros((1, K))\n",
        "    rot_imgs = np.zeros((dims[0], dims[1]*Ndeg))\n",
        "    for i,deg in enumerate(np.linspace(0, Mdeg, Ndeg)):\n",
        "        rot_img = nd.rotate(img.reshape(*dims), deg, reshape=False).reshape(*dims)\n",
        "        rot_img = np.clip(a=rot_img, a_min=0, a_max=1)\n",
        "        rot_imgs[:,i*dims[1]:(i+1)*dims[1]] = 1 - rot_img\n",
        "        feed_dict={X:rot_img.reshape(1,-1), keep_prob:1.0}\n",
        "        if uncertainty is None:\n",
        "            p_pred_t = sess.run(prob, feed_dict=feed_dict)\n",
        "        else:\n",
        "            p_pred_t,u = sess.run([prob,uncertainty], feed_dict=feed_dict)\n",
        "            lu.append(u.mean())\n",
        "        scores += p_pred_t >= threshold\n",
        "        ldeg.append(deg) \n",
        "        lp.append(p_pred_t[0])\n",
        "    \n",
        "    labels = np.arange(K)[scores[0].astype(bool)]\n",
        "    lp = np.array(lp)[:,labels]\n",
        "    labels = labels.tolist()\n",
        "    \n",
        "    plt.figure(figsize=[6,6])\n",
        "    for i in range(len(labels)):\n",
        "        plt.plot(ldeg, lp[:,i], marker=marker[i], c=c[i])\n",
        "    \n",
        "    if uncertainty is not None:\n",
        "        labels += ['uncertainty']\n",
        "        plt.plot(ldeg,lu,marker='<',c='red')\n",
        "        \n",
        "    plt.legend(labels)\n",
        " \n",
        "    plt.xlim([0,Mdeg])  \n",
        "    plt.xlabel('Rotation Degree')\n",
        "    plt.ylabel('Classification Probability')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=[6.4,100])\n",
        "    plt.imshow(rot_imgs,cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcrzWcsvZ8jZ",
        "colab_type": "text"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHnpCVOqaDv8",
        "colab_type": "text"
      },
      "source": [
        "##### LeNet with softmax cross entropy loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVy1cHeRZvVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def var(name, shape, init=None):\n",
        "    init = tf.truncated_normal_initializer(stddev=(2/shape[0])**0.5) if init is None else init\n",
        "    return tf.get_variable(name=name, shape=shape, dtype=tf.float32, initializer=init)\n",
        "\n",
        "def LeNet_softmax(K, lmb=0.005, dims=(28,28), nch=1): \n",
        "    g = tf.Graph()\n",
        "    with g.as_default():\n",
        "        X = tf.placeholder(shape=[None,np.prod(dims)*nch], dtype=tf.float32)\n",
        "        Y = tf.placeholder(shape=[None,K], dtype=tf.float32)\n",
        "        keep_prob = tf.placeholder(dtype=tf.float32)\n",
        "        \n",
        "        W1 = var('W1', [5,5,nch,20])\n",
        "        b1 = var('b1', [20])\n",
        "        c1 = tf.nn.conv2d(tf.reshape(X, [-1, *dims, nch]), W1, [1, 1, 1, 1], 'SAME')\n",
        "        r1 = tf.nn.relu(c1 + b1)\n",
        "        out1 = tf.nn.max_pool(r1, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
        "        \n",
        "        W2 = var('W2', [5,5,20,50])\n",
        "        b2 = var('b2', [50])\n",
        "        c2 = tf.nn.conv2d(out1, W2, [1, 1, 1, 1], 'SAME')\n",
        "        r2 = tf.nn.relu(c2 + b2)\n",
        "        out2 = tf.nn.max_pool(r2, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
        "        \n",
        "        Xflat = tf.contrib.layers.flatten(out2)\n",
        "\n",
        "        W3 = var('W3', [Xflat.get_shape()[1].value, 500])\n",
        "        b3 = var('b3', [500]) \n",
        "        out3 = tf.nn.relu(tf.matmul(Xflat, W3) + b3)\n",
        "        out3 = tf.nn.dropout(out3, keep_prob=keep_prob)\n",
        "\n",
        "        W4 = var('W4', [500,K])\n",
        "        b4 = var('b4', [K])\n",
        "        logits = tf.matmul(out3, W4) + b4\n",
        "        \n",
        "        prob = tf.nn.softmax(logits=logits) \n",
        "        \n",
        "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
        "        l2_loss = (tf.nn.l2_loss(W3)+tf.nn.l2_loss(W4)) * lmb\n",
        "        \n",
        "        step = tf.train.AdamOptimizer().minimize(loss + l2_loss)\n",
        "        \n",
        "        acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(prob, 1), tf.argmax(Y, 1)), tf.float32))\n",
        "        \n",
        "        return g, step, X, Y, keep_prob, prob, acc, loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0G8j59taKm7",
        "colab_type": "text"
      },
      "source": [
        "##### LeNet with expected mean square error loss <font color=red>(Add the loss for out of distributino)</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wy5T8Y-aLCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def var(name, shape, init=None):\n",
        "    init = tf.truncated_normal_initializer(stddev=(2/shape[0])**0.5) if init is None else init\n",
        "    return tf.get_variable(name=name, shape=shape, dtype=tf.float32, initializer=init)\n",
        "  \n",
        "def LeNet_EDL(K, loss_function, logits2evidence=relu_evidence, lmb=0.005, dims=(28,28), nch=1):\n",
        "    g = tf.Graph()\n",
        "    with g.as_default():\n",
        "        X = tf.placeholder(shape=[None,np.prod(dims)*nch], dtype=tf.float32)\n",
        "        Y = tf.placeholder(shape=[None,K], dtype=tf.float32)\n",
        "        keep_prob = tf.placeholder(dtype=tf.float32)\n",
        "        out_statue = tf.placeholder_with_default(False, shape=()) # control the uncertainty regularization loss\n",
        "\n",
        "        global_step = tf.Variable(initial_value=0, name='global_step', trainable=False)\n",
        "        annealing_step = tf.placeholder(dtype=tf.int32) \n",
        "    \n",
        "        W1 = var('W1', [5,5,nch,20])\n",
        "        b1 = var('b1', [20])\n",
        "        c1 = tf.nn.conv2d(tf.reshape(X, [-1, *dims, nch]), W1, [1, 1, 1, 1], 'SAME')\n",
        "        r1 = tf.nn.relu(c1 + b1)\n",
        "        out1 = tf.nn.max_pool(r1, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
        "        \n",
        "        W2 = var('W2', [5,5,20,50])\n",
        "        b2 = var('b2', [50])\n",
        "        c2 = tf.nn.conv2d(out1, W2, [1, 1, 1, 1], 'SAME')\n",
        "        r2 = tf.nn.relu(c2 + b2)\n",
        "        out2 = tf.nn.max_pool(r2, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
        "\n",
        "        Xflat = tf.contrib.layers.flatten(out2)\n",
        "\n",
        "        W3 = var('W3', [Xflat.get_shape()[1].value, 500])\n",
        "        b3 = var('b3', [500]) \n",
        "        out3 = tf.nn.relu(tf.matmul(Xflat, W3) + b3)\n",
        "        out3 = tf.nn.dropout(out3, keep_prob=keep_prob)\n",
        "\n",
        "        W4 = var('W4', [500,K])\n",
        "        b4 = var('b4', [K])\n",
        "        logits = tf.matmul(out3, W4) + b4\n",
        "        \n",
        "        evidence = logits2evidence(logits)\n",
        "        alpha = evidence + 1\n",
        "        \n",
        "        u = K / tf.reduce_sum(alpha, axis=1, keepdims=True)\n",
        "        \n",
        "        prob = alpha/tf.reduce_sum(alpha, 1, keepdims=True) \n",
        "        \n",
        "        loss = tf.cond(out_statue, lambda: 0.01*tf.reduce_mean(1-u), lambda: tf.reduce_mean(loss_function(Y, alpha, K, global_step, annealing_step)))\n",
        "\n",
        "        # loss = tf.reduce_mean(loss_function(Y, alpha, K, global_step, annealing_step))\n",
        "        l2_loss = (tf.nn.l2_loss(W3)+tf.nn.l2_loss(W4)) * lmb\n",
        "        \n",
        "        step = tf.train.AdamOptimizer().minimize(loss + l2_loss, global_step=global_step)\n",
        "        \n",
        "        match = tf.reshape(tf.cast(tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1)), tf.float32),(-1,1))\n",
        "        acc = tf.reduce_mean(match)\n",
        "        \n",
        "        total_evidence = tf.reduce_sum(evidence,1, keepdims=True) \n",
        "        mean_ev = tf.reduce_mean(total_evidence)\n",
        "        mean_ev_succ = tf.reduce_sum(tf.reduce_sum(evidence,1, keepdims=True)*match) / tf.reduce_sum(match+1e-20)\n",
        "        mean_ev_fail = tf.reduce_sum(tf.reduce_sum(evidence,1, keepdims=True)*(1-match)) / (tf.reduce_sum(tf.abs(1-match))+1e-20) \n",
        "        \n",
        "        return g, step, X, Y, annealing_step, keep_prob, prob, acc, loss, u, evidence, mean_ev, mean_ev_succ, mean_ev_fail, out_statue, logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w1XT2WfdEr2",
        "colab_type": "text"
      },
      "source": [
        "##### LeNet with expected mean square error loss <font color=yellow>(Add the loss for dissonance and vacuity)</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjTkuVMUdI0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def var(name, shape, init=None):\n",
        "    init = tf.truncated_normal_initializer(stddev=(2/shape[0])**0.5) if init is None else init\n",
        "    return tf.get_variable(name=name, shape=shape, dtype=tf.float32, initializer=init)\n",
        "  \n",
        "def LeNet_EDL_D(K, loss_function, logits2evidence=relu_evidence, lmb=0.005, dims=(28,28), nch=1):\n",
        "    g = tf.Graph()\n",
        "    with g.as_default():\n",
        "        X = tf.placeholder(shape=[None,np.prod(dims)*nch], dtype=tf.float32)\n",
        "        Y = tf.placeholder(shape=[None,K], dtype=tf.float32)\n",
        "        keep_prob = tf.placeholder(dtype=tf.float32)\n",
        "        out_statue = tf.placeholder_with_default(False, shape=()) # control the uncertainty regularization loss\n",
        "        d_mask = tf.placeholder(tf.int32)\n",
        "\n",
        "        global_step = tf.Variable(initial_value=0, name='global_step', trainable=False)\n",
        "        annealing_step = tf.placeholder(dtype=tf.int32) \n",
        "    \n",
        "        W1 = var('W1', [5,5,nch,20])\n",
        "        b1 = var('b1', [20])\n",
        "        c1 = tf.nn.conv2d(tf.reshape(X, [-1, *dims, nch]), W1, [1, 1, 1, 1], 'SAME')\n",
        "        r1 = tf.nn.relu(c1 + b1)\n",
        "        out1 = tf.nn.max_pool(r1, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
        "        \n",
        "        W2 = var('W2', [5,5,20,50])\n",
        "        b2 = var('b2', [50])\n",
        "        c2 = tf.nn.conv2d(out1, W2, [1, 1, 1, 1], 'SAME')\n",
        "        r2 = tf.nn.relu(c2 + b2)\n",
        "        out2 = tf.nn.max_pool(r2, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
        "\n",
        "        Xflat = tf.contrib.layers.flatten(out2)\n",
        "\n",
        "        W3 = var('W3', [Xflat.get_shape()[1].value, 500])\n",
        "        b3 = var('b3', [500]) \n",
        "        out3 = tf.nn.relu(tf.matmul(Xflat, W3) + b3)\n",
        "        out3 = tf.nn.dropout(out3, keep_prob=keep_prob)\n",
        "\n",
        "        W4 = var('W4', [500,K])\n",
        "        b4 = var('b4', [K])\n",
        "        logits = tf.matmul(out3, W4) + b4\n",
        "        \n",
        "        evidence = logits2evidence(logits)\n",
        "        alpha = evidence + 1\n",
        "        \n",
        "        u = K / tf.reduce_sum(alpha, axis=1, keepdims=True)\n",
        "        \n",
        "        prob = alpha/tf.reduce_sum(alpha, 1, keepdims=True) \n",
        "        \n",
        "        dissonance = dissonance_tf(evidence)\n",
        "        \n",
        "        loss = tf.cond(out_statue, lambda: 0.01*tf.reduce_mean(1-u), lambda: tf.reduce_mean(loss_function(Y, alpha, K, global_step, annealing_step)) - 0.01 * masked_dissonance_loss(dissonance, d_mask))\n",
        "        \n",
        "#         dissonance = dissonance_tf(evidence)\n",
        "        \n",
        "#         loss_dissonance = 0.01 * masked_dissonance_loss(dissonance, d_mask)\n",
        "        \n",
        "#         loss += loss_dissonance\n",
        "        \n",
        "        # loss = tf.reduce_mean(loss_function(Y, alpha, K, global_step, annealing_step))\n",
        "        l2_loss = (tf.nn.l2_loss(W3)+tf.nn.l2_loss(W4)) * lmb\n",
        "        \n",
        "        step = tf.train.AdamOptimizer().minimize(loss + l2_loss, global_step=global_step)\n",
        "        \n",
        "        match = tf.reshape(tf.cast(tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1)), tf.float32),(-1,1))\n",
        "        acc = tf.reduce_mean(match)\n",
        "        \n",
        "        total_evidence = tf.reduce_sum(evidence,1, keepdims=True) \n",
        "        mean_ev = tf.reduce_mean(total_evidence)\n",
        "        mean_ev_succ = tf.reduce_sum(tf.reduce_sum(evidence,1, keepdims=True)*match) / tf.reduce_sum(match+1e-20)\n",
        "        mean_ev_fail = tf.reduce_sum(tf.reduce_sum(evidence,1, keepdims=True)*(1-match)) / (tf.reduce_sum(tf.abs(1-match))+1e-20) \n",
        "        \n",
        "        return g, step, X, Y, annealing_step, keep_prob, prob, acc, loss, u, evidence, mean_ev, mean_ev_succ, mean_ev_fail, out_statue, logits, dissonance, d_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjJZE91xaZJy",
        "colab_type": "text"
      },
      "source": [
        "### Model trainings and testings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZJBpnrTeH2I",
        "colab_type": "text"
      },
      "source": [
        "##### Only Softmax (Regular LeNet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-PhblgFazIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g, step, X, Y, keep_prob, prob, acc, loss = LeNet_softmax(K=10)\n",
        "sess = tf.Session(graph=g)\n",
        "with g.as_default(): \n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "epoch = 50\n",
        "bsize = 1000\n",
        "n_batches = mnist.train.num_examples // bsize\n",
        "for e in range(epoch):   \n",
        "    for i in range(n_batches):\n",
        "        data, label = mnist.train.next_batch(bsize)\n",
        "        sess.run(step, {X:data, Y:label, keep_prob:.5})\n",
        "        print('epoch %d - %d%%) '% (e+1, (100*(i+1))//n_batches), end='\\r' if i<n_batches-1 else '')\n",
        "        \n",
        "    train_acc = sess.run(acc, feed_dict={X:mnist.train.images, Y:mnist.train.labels, keep_prob:1.})\n",
        "    test_acc = sess.run(acc, feed_dict={X:mnist.test.images, Y:mnist.test.labels, keep_prob:1.})\n",
        "    \n",
        "    print('training accuracy: %2.4f \\t testing accuracy: %2.4f' % (train_acc, test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_MycW3YbgcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rotating_image_classification(digit, sess, prob, X, keep_prob, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpWlabiJqsqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nm_p_sm = sess.run(prob, feed_dict={X:notmnist_x,Y:notmnist_y,keep_prob:1.}).copy()\n",
        "entropies_sm = [scipy.stats.entropy(nm_p_sm[i,:]) for i in range(nm_p_sm.shape[0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GyG4zMTwg2Q",
        "colab_type": "text"
      },
      "source": [
        "As you see, the model fails when a **training** data is started to be rotated. It predicts the correct class up to 5-10 degrees, and then starts to fail to assign that specific class as the output. The dramatic part of this failure starts with assigning another class instead of the correct class since regular NNs like this LeNet implementation should always produce a class label as the output as it does not have any other option. As the sample rotated, the assigned class changes sometimes even multiple times. This example shows how the network fails handling an out-of-distribution sample. Another example could be using a nonMNIST data as the test sample where the NN would fail again by saying \"3\" or \"5\" or any other digit to a non-digit sample.\n",
        "\n",
        "These type of failures are stated as out-of-distribution failures in the paper. One other failure is shown where the input is from the distribution, but it's distorted in a special way so that it is completely normal to a human whereas the network interprets it as a completely irrelevant class with >99% accuracy. An example can be shown below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i9Kxc8oyPpj",
        "colab_type": "text"
      },
      "source": [
        "Here, when an image of digit 9 is rotated, it will be stated to be recognized as 5, 8 or some other digit until it is rotated 180 degrees which corresponds to digit 6 as expected. Below, the proposed network (training an uncertainty as well, with the proposed different loss functions) will be used to overcome uncertainty issue explained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqwviRmXmKT6",
        "colab_type": "text"
      },
      "source": [
        "##### Using the Expected Mean Square Error (Eq. 5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLlcT8uZfDV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "tf.set_random_seed(seed)\n",
        "\n",
        "g, step, X, Y, annealing_step, keep_prob, prob, acc, loss, u, evidence, mean_ev, mean_ev_succ, mean_ev_fail, out_statue, logits = LeNet_EDL(10, loss_eq5, relu_evidence)\n",
        "sess = tf.Session(graph=g)\n",
        "\n",
        "with g.as_default():\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "epoch = 50\n",
        "bsize = 1000\n",
        "n_batches = mnist.train.num_examples // bsize\n",
        "m_batchs = len(notmnist_x) // n_batches\n",
        "L_train_acc=[]\n",
        "L_train_ev_s=[]\n",
        "L_train_ev_f=[]\n",
        "L_test_acc=[]\n",
        "L_test_ev_s=[]\n",
        "L_test_ev_f=[]\n",
        "for e in range(epoch):   \n",
        "    for i in range(n_batches):\n",
        "        data, label = mnist.train.next_batch(bsize)\n",
        "        sess.run(step, feed_dict={X:data, Y:label, keep_prob:.5, annealing_step:10*n_batches})\n",
        "        print('epoch %d - %d%%) '% (e+1, (100*(i+1))//n_batches), end='\\r' if i<n_batches-1 else '')\n",
        "        \n",
        "    train_acc, train_succ, train_fail = sess.run([acc,mean_ev_succ,mean_ev_fail], feed_dict={X:mnist.train.images, Y:mnist.train.labels, keep_prob:1.})\n",
        "    test_acc, test_succ, test_fail = sess.run([acc,mean_ev_succ,mean_ev_fail], feed_dict={X:mnist.test.images, Y:mnist.test.labels, keep_prob:1.})\n",
        "    \n",
        "    L_train_acc.append(train_acc)\n",
        "    L_train_ev_s.append(train_succ)\n",
        "    L_train_ev_f.append(train_fail)\n",
        "    \n",
        "    L_test_acc.append(test_acc)\n",
        "    L_test_ev_s.append(test_succ)\n",
        "    L_test_ev_f.append(test_fail)\n",
        "    \n",
        "    print('training: %2.4f (%2.4f - %2.4f) \\t testing: %2.4f (%2.4f - %2.4f)' % \n",
        "          (train_acc, train_succ, train_fail, test_acc, test_succ, test_fail))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHmFZGRomRfh",
        "colab_type": "text"
      },
      "source": [
        "##### Using the Expected Mean Square Error (Eq. 5) + Vacuity regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3Xzl4bxbqNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "tf.set_random_seed(seed)\n",
        "\n",
        "g, step, X, Y, annealing_step, keep_prob, prob, acc, loss, u, evidence, mean_ev, mean_ev_succ, mean_ev_fail, out_statue, logits= LeNet_EDL(10, loss_eq5, relu_evidence)\n",
        "sess = tf.Session(graph=g)\n",
        "\n",
        "with g.as_default():\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "epoch = 50\n",
        "bsize = 1000\n",
        "n_batches = mnist.train.num_examples // bsize\n",
        "m_batchs = len(notmnist_x) // n_batches\n",
        "L_train_acc=[]\n",
        "L_train_ev_s=[]\n",
        "L_train_ev_f=[]\n",
        "L_test_acc=[]\n",
        "L_test_ev_s=[]\n",
        "L_test_ev_f=[]\n",
        "for e in range(epoch):   \n",
        "    for i in range(n_batches):\n",
        "        data, label = mnist.train.next_batch(bsize)\n",
        "        sess.run(step, feed_dict={X:data, Y:label, keep_prob:.5, annealing_step:10*n_batches})\n",
        "        print('epoch %d - %d%%) '% (e+1, (100*(i+1))//n_batches), end='\\r' if i<n_batches-1 else '')\n",
        "        data = notmnist_x[i * m_batchs:(i + 1) * m_batchs]\n",
        "        label = notmnist_y[i * m_batchs:(i + 1) * m_batchs]\n",
        "        sess.run(step, feed_dict={X: data, Y: label, keep_prob: .5, annealing_step: 10 * n_batches, out_statue: True})\n",
        "        \n",
        "    train_acc, train_succ, train_fail = sess.run([acc,mean_ev_succ,mean_ev_fail], feed_dict={X:mnist.train.images, Y:mnist.train.labels, keep_prob:1.})\n",
        "    test_acc, test_succ, test_fail = sess.run([acc,mean_ev_succ,mean_ev_fail], feed_dict={X:mnist.test.images, Y:mnist.test.labels, keep_prob:1.})\n",
        "    \n",
        "    L_train_acc.append(train_acc)\n",
        "    L_train_ev_s.append(train_succ)\n",
        "    L_train_ev_f.append(train_fail)\n",
        "    \n",
        "    L_test_acc.append(test_acc)\n",
        "    L_test_ev_s.append(test_succ)\n",
        "    L_test_ev_f.append(test_fail)\n",
        "    \n",
        "    print('training: %2.4f (%2.4f - %2.4f) \\t testing: %2.4f (%2.4f - %2.4f)' % \n",
        "          (train_acc, train_succ, train_fail, test_acc, test_succ, test_fail))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN-PozjOcM9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "draw_EDL_results(10, L_train_acc, L_train_ev_s, L_train_ev_f, L_test_acc, L_test_ev_s, L_test_ev_f)\n",
        "rotating_image_classification(digit, sess, prob, X, keep_prob, 10, u)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G5k9Uv6yd3g",
        "colab_type": "text"
      },
      "source": [
        "As you see, the network now starts to say \"*I don't know*\" to the examples of out-of-distribution with very high probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23-cZfoLrAy7",
        "colab_type": "text"
      },
      "source": [
        "Let us test the standard Softmax and EDL models' uncertainty assignment ability by testing the model trained on MNIST with notMNIST dataset.\n",
        "We look at the entropies of the predictive probabilities when model is fed with out-of-distribution data. We expect the expected entropy to be high (curve closer to bottom right corner is better)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ql18JGtq1UZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nm_p_edl1 = sess.run(prob, feed_dict={X:notmnist_x,Y:notmnist_y,keep_prob:1.}).copy()\n",
        "entropies_edl1 = [scipy.stats.entropy(nm_p_edl1[i,:]) for i in range(nm_p_edl1.shape[0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA-zIEf5uhCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nm_p_edl_v = sess.run(prob, feed_dict={X:notmnist_x,Y:notmnist_y,keep_prob:1.}).copy()\n",
        "entropies_edl_v = [scipy.stats.entropy(nm_p_edl_v[i,:]) for i in range(nm_p_edl_v.shape[0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YfdA6OIrF0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cdf_sm = np.histogram(entropies_sm, bins=1000)[0];\n",
        "cdf_sm = cdf_sm / np.sum(cdf_sm)\n",
        "cdf_sm = np.cumsum(cdf_sm)\n",
        "cdf_edl1 = np.histogram(entropies_edl1,bins=1000)[0];\n",
        "cdf_edl1 = cdf_edl1 / np.sum(cdf_edl1)\n",
        "cdf_edl1 = np.cumsum(cdf_edl1)\n",
        "cdf_edl_v = np.histogram(entropies_edl_v,bins=1000)[0];\n",
        "cdf_edl_v = cdf_edl_v / np.sum(cdf_edl_v)\n",
        "cdf_edl_v = np.cumsum(cdf_edl_v)\n",
        "xaxs= np.linspace(0,np.log(10),1000)\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(xaxs,cdf_sm,label=\"Softmax\", color='r')\n",
        "plt.plot(xaxs,cdf_edl1, label=\"EDL\", color=\"b\")\n",
        "plt.plot(xaxs,cdf_edl_v, label=\"EDL_V\", color=\"g\")\n",
        "\n",
        "plt.legend(loc='upper left')\n",
        "plt.xlim(0,np.log(10)+0.03)\n",
        "plt.ylim(0,1.01)\n",
        "plt.xlabel(\"Entropy\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.title(\"CDF for the entropy of the predictive distributions\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ydv-WML1e-H",
        "colab_type": "text"
      },
      "source": [
        "####Traing Cifar 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0_ogcvPRMpT",
        "colab_type": "text"
      },
      "source": [
        "##### Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1eptpG-rUFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g, step, X, Y, keep_prob, prob, acc, loss = LeNet_softmax(K=5, dims=(32,32), nch=3)\n",
        "sess = tf.Session(graph=g)\n",
        "with g.as_default(): \n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "epoch = 50\n",
        "bsize = 1000\n",
        "n_batches = cifar5_x_train.shape[0] // bsize\n",
        "for e in range(epoch):   \n",
        "    train_acc = 0.\n",
        "    for i in range(n_batches):\n",
        "        data = cifar5_x_train[i*bsize:min((i+1)*bsize, cifar5_x_train.shape[0]),:]\n",
        "        label = cifar5_y_train[i*bsize:min((i+1)*bsize, cifar5_y_train.shape[0]),:]\n",
        "        sess.run(step, {X:data, Y:label, keep_prob:.9})\n",
        "\n",
        "        print('epoch %d - %d%%) '% (e+1, (100*(i+1))//n_batches), end='\\r' if i<n_batches-1 else '')\n",
        "    accur_final=sess.run(acc, {X:cifar5_x_train, Y:cifar5_y_train, keep_prob:1.})\n",
        "    print('training accuracy: %2.4f' % (accur_final, ))\n",
        "    acc_test = sess.run(acc, {X:cifar5_x_train_test, Y:cifar5_y_train_test, keep_prob:1.})\n",
        "    print('test accuracy: %2.4f' % (acc_test,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv-M-74F9tmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(cifar5_x_train.shape[0])\n",
        "print(cifar5_x_ood_train.shape[0])\n",
        "print(cifar5_x_ood_test.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soueV7x8rkaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "entropies_c5_sm = []\n",
        "for i in range(6):\n",
        "  nm_p_c5_sm = sess.run(prob, feed_dict={X:cifar5_x_ood_test[i*2500:(i+1)*2500],Y:cifar5_y_ood_test[i*2500:(i+1)*2500],keep_prob:1.}).copy()\n",
        "  entropies_c5_sm += [scipy.stats.entropy(nm_p_c5_sm[i,:]) for i in range(2500)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKi-L2iHRQkU",
        "colab_type": "text"
      },
      "source": [
        "##### EDL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhoay38ErmdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g, step, X, Y, annealing_step, keep_prob, prob, acc, loss, u, evidence, mean_ev, mean_ev_succ, mean_ev_fail, out_statue, logits = LeNet_EDL(5, loss_eq5, relu_evidence, dims=(32,32), nch=3)\n",
        "sess = tf.Session(graph=g)\n",
        "with g.as_default():\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "epoch = 50\n",
        "bsize = 1000\n",
        "n_batches = cifar5_x_train.shape[0] // bsize\n",
        "for e in range(epoch):   \n",
        "    train_acc = 0.\n",
        "    for i in range(n_batches):\n",
        "        data = cifar5_x_train[i*bsize:min((i+1)*bsize, cifar5_x_train.shape[0]),:]\n",
        "        label = cifar5_y_train[i*bsize:min((i+1)*bsize, cifar5_y_train.shape[0]),:]\n",
        "        sess.run(step, feed_dict={X:data, Y:label, keep_prob:.9, annealing_step:50*n_batches})\n",
        "#         accur = sess.run(acc, feed_dict={X:data, Y:label, keep_prob:1.})\n",
        "#         train_acc += accur\n",
        "        print('epoch %d - %d%%) '% (e+1, (100*(i+1))//n_batches), end='\\r' if i<n_batches-1 else '')\n",
        "    accur_final, logits_final=sess.run([acc, logits], {X:cifar5_x_train, Y:cifar5_y_train, keep_prob:1.})\n",
        "    print('training accuracy: %2.4f' % (accur_final,))\n",
        "    accur_final, logits_final=sess.run([acc, logits], {X:cifar5_x_train_test, Y:cifar5_y_train_test, keep_prob:1.})\n",
        "    print('test accuracy: %2.4f' % (accur_final,))\n",
        "#     print(logits_final[:5])\n",
        "#     print('training: %2.4f' % (train_acc / n_batches, ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gt_Y5T6rqpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "entropies_c5_edl1 = []\n",
        "for i in range(6):\n",
        "  nm_p_c5_edl1 = sess.run(prob, feed_dict={X:cifar5_x_ood_test[i*2500:(i+1)*2500],Y:cifar5_y_ood_test[i*2500:(i+1)*2500],keep_prob:1.}).copy()\n",
        "  entropies_c5_edl1 += [scipy.stats.entropy(nm_p_c5_edl1[i,:]) for i in range(2500)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dItoX0pE75v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "entropies_c5_edl1_in = []\n",
        "for i in range(2):\n",
        "  nm_p_c5_edl1_in = sess.run(prob, feed_dict={X:cifar5_x_train_test[i*2500:(i+1)*2500],Y:cifar5_y_train_test[i*2500:(i+1)*2500],keep_prob:1.}).copy()\n",
        "  entropies_c5_edl1_in += [scipy.stats.entropy(nm_p_c5_edl1_in[i,:]) for i in range(2500)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6mdwOFpQ8kx",
        "colab_type": "text"
      },
      "source": [
        "#####  <font color=yellow>Training with dissonance</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3hsIPDYRA35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g, step, X, Y, annealing_step, keep_prob, prob, acc, loss, u, evidence, mean_ev, mean_ev_succ, mean_ev_fail, out_statue, logits, dissonance, d_mask = LeNet_EDL_D(5, loss_eq5, relu_evidence, dims=(32,32), nch=3)\n",
        "sess = tf.Session(graph=g)\n",
        "with g.as_default():\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "epoch = 50\n",
        "bsize = 1000\n",
        "n_batches = cifar5_x_train.shape[0] // bsize\n",
        "for e in range(epoch):   \n",
        "    for i in range(n_batches):\n",
        "        data = cifar5_x_train[i*bsize:min((i+1)*bsize, cifar5_x_train.shape[0]),:]\n",
        "        label = cifar5_y_train[i*bsize:min((i+1)*bsize, cifar5_y_train.shape[0]),:]\n",
        "        sess.run(step, feed_dict={X:data, Y:label, keep_prob:.9, annealing_step:50*n_batches, out_statue:False, d_mask:dissonance_mask[i]})\n",
        "        \n",
        "        if e > 30:\n",
        "          data_ood = cifar5_x_ood_train[i*m_batches:min((i+1)*m_batches, cifar5_x_ood_train.shape[0]),:]\n",
        "          label_ood = cifar5_y_ood_train[i*m_batches:min((i+1)*m_batches, cifar5_y_ood_train.shape[0]),:]\n",
        "          sess.run(step, feed_dict={X:data_ood, Y:label_ood, keep_prob:.9, annealing_step:50*n_batches, out_statue:True, d_mask:dissonance_mask[i]})\n",
        "        \n",
        "        print('epoch %d - %d%%) '% (e+1, (100*(i+1))//n_batches), end='\\r' if i<n_batches-1 else '')\n",
        "    accur_final, evi, dis =sess.run([acc, evidence, dissonance], {X:cifar5_x_train, Y:cifar5_y_train, keep_prob:1.})\n",
        "    print('training accuracy: %2.4f' % (accur_final,))\n",
        "    print('Average dissonance: ', np.mean(dis))\n",
        "    accur_final, logits_final=sess.run([acc, logits], {X:cifar5_x_train_test, Y:cifar5_y_train_test, keep_prob:1.})\n",
        "    print('test accuracy: %2.4f' % (accur_final,))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crdr4Gikh4Bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "entropies_c5_edl_d = []\n",
        "for i in range(6):\n",
        "  nm_p_c5_edl_d = sess.run(prob, feed_dict={X:cifar5_x_ood_test[i*2500:(i+1)*2500],Y:cifar5_y_ood_test[i*2500:(i+1)*2500],keep_prob:1.}).copy()\n",
        "  entropies_c5_edl_d += [scipy.stats.entropy(nm_p_c5_edl_d[i,:]) for i in range(2500)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLZiKzYv-zOd",
        "colab_type": "text"
      },
      "source": [
        "##### Vacuity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEpuFTAy-woh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g, step, X, Y, annealing_step, keep_prob, prob, acc, loss, u, evidence, mean_ev, mean_ev_succ, mean_ev_fail, out_statue, logits= LeNet_EDL(5, loss_eq5, relu_evidence, dims=(32,32), nch=3)\n",
        "sess = tf.Session(graph=g)\n",
        "with g.as_default():\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "epoch = 50\n",
        "bsize = 1000\n",
        "n_batches = cifar5_x_train.shape[0] // bsize\n",
        "m_batches = cifar5_x_ood_train.shape[0] // n_batches\n",
        "for e in range(epoch):   \n",
        "    train_acc = 0.\n",
        "    for i in range(n_batches):\n",
        "        data = cifar5_x_train[i*bsize:min((i+1)*bsize, cifar5_x_train.shape[0]),:]\n",
        "        label = cifar5_y_train[i*bsize:min((i+1)*bsize, cifar5_y_train.shape[0]),:]\n",
        "        sess.run(step, feed_dict={X:data, Y:label, keep_prob:.9, annealing_step:50*n_batches, out_statue:False})\n",
        "        \n",
        "        if e > 30:\n",
        "          data_ood = cifar5_x_ood_train[i*m_batches:min((i+1)*m_batches, cifar5_x_ood_train.shape[0]),:]\n",
        "          label_ood = cifar5_y_ood_train[i*m_batches:min((i+1)*m_batches, cifar5_y_ood_train.shape[0]),:]\n",
        "          sess.run(step, feed_dict={X:data_ood, Y:label_ood, keep_prob:.9, annealing_step:50*n_batches, out_statue:True})\n",
        "        \n",
        "\n",
        "\n",
        "        print('epoch %d - %d%%) '% (e+1, (100*(i+1))//n_batches), end='\\r' if i<n_batches-1 else '')\n",
        "    accur_final, logits_final=sess.run([acc, logits], {X:cifar5_x_train, Y:cifar5_y_train, keep_prob:1.})\n",
        "    print('training accuracy: %2.4f' % (accur_final,))\n",
        "    accur_final, logits_final=sess.run([acc, logits], {X:cifar5_x_train_test, Y:cifar5_y_train_test, keep_prob:1.})\n",
        "    print('test accuracy: %2.4f' % (accur_final,))\n",
        "#     print(logits_final[:5])\n",
        "#     print('training: %2.4f' % (train_acc / n_batches, ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX7_47muBhDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "entropies_c5_edl_v = []\n",
        "for i in range(6):\n",
        "  nm_p_c5_edl_v = sess.run(prob, feed_dict={X:cifar5_x_ood_test[i*2500:(i+1)*2500],Y:cifar5_y_ood_test[i*2500:(i+1)*2500],keep_prob:1.}).copy()\n",
        "  entropies_c5_edl_v += [scipy.stats.entropy(nm_p_c5_edl_v[i,:]) for i in range(2500)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikWMaKD8RVwF",
        "colab_type": "text"
      },
      "source": [
        "##### Draw fig"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgeKR2FyrseL",
        "colab_type": "code",
        "outputId": "45b990d2-2bc1-4183-a8a9-25e6ad5e5a77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "cdf_sm = np.histogram(entropies_c5_sm, bins=1000)[0];\n",
        "cdf_sm = cdf_sm / np.sum(cdf_sm)\n",
        "cdf_sm = np.cumsum(cdf_sm)\n",
        "cdf_edl1 = np.histogram(entropies_c5_edl1,bins=1000)[0];\n",
        "cdf_edl1 = cdf_edl1 / np.sum(cdf_edl1)\n",
        "cdf_edl1 = np.cumsum(cdf_edl1)\n",
        "cdf_edl_v = np.histogram(entropies_c5_edl_v,bins=1000)[0];\n",
        "cdf_edl_v = cdf_edl_v / np.sum(cdf_edl_v)\n",
        "cdf_edl_v = np.cumsum(cdf_edl_v)\n",
        "cdf_edl_d = np.histogram(entropies_c5_edl_d,bins=1000)[0];\n",
        "cdf_edl_d = cdf_edl_d / np.sum(cdf_edl_d)\n",
        "cdf_edl_d = np.cumsum(cdf_edl_d)\n",
        "\n",
        "cdf_edl1_in = np.histogram(entropies_c5_edl1_in,bins=1000)[0];\n",
        "cdf_edl1_in = cdf_edl1_in / np.sum(cdf_edl1_in)\n",
        "cdf_edl1_in = np.cumsum(cdf_edl1_in)\n",
        "\n",
        "np.save('softmax_result.npy', entropies_c5_sm)\n",
        "np.save('EDL_result.npy', entropies_c5_edl1)\n",
        "np.save('EDL_vacuity_result.npy', entropies_c5_edl_v)\n",
        "np.save('EDL_dissonance_result.npy', entropies_c5_edl_d)\n",
        "\n",
        "\n",
        "xaxs= np.linspace(0,np.log(5),1000)\n",
        "print(np.mean(cdf_sm), np.mean(cdf_edl1), np.mean(cdf_edl_v), np.mean(cdf_edl_d))\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(xaxs,cdf_sm,label=\"Softmax\", color='r')\n",
        "plt.plot(xaxs,cdf_edl1, label=\"EDL\", color=\"b\")\n",
        "plt.plot(xaxs,cdf_edl_v, label=\"EDL_vacity\", color=\"g\")\n",
        "plt.plot(xaxs,cdf_edl_d, label=\"EDL_dissonance\", color=\"y\")\n",
        "# plt.plot(xaxs,cdf_edl1_in, label=\"EDL_in\", color=\"k\")\n",
        "\n",
        "\n",
        "plt.legend(loc='upper left')\n",
        "plt.xlim(0,np.log(5)+0.03)\n",
        "plt.ylim(0,1.01)\n",
        "plt.xlabel(\"Entropy\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.title(\"CDF for the entropy of the predictive distributions\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5421720000000005 0.18174379999999993 0.0888169333333332 0.18651373333333315\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVUAAAFNCAYAAACwifzYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXkSbqkaj0XiR/wcIt4c+xrY+FwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRDN-M4zrubU",
        "colab_type": "text"
      },
      "source": [
        "In above plot, we see the CDFs of entropies of Softmax and EDL models trained with the first 5 classes of CIFAR10 dataset and tested with the last 5 classes (out-of-distribution). Again we observe that EDL yields higher entropy for these instances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPClEJC9bBfI",
        "colab_type": "text"
      },
      "source": [
        "## Acknowledgments\n",
        "Our work and code benefit from this existing works, which we are very grateful.\n",
        "\n",
        "EDL : https://github.com/atilberk/evidential-deep-learning-to-quantify-classification-uncertainty"
      ]
    }
  ]
}